<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Huang Yujie&#39;s Blog</title>
  <icon>https://www.gravatar.com/avatar/bb904430b38398d2d1ab671d0d4cc8de</icon>
  <subtitle>Welcome to my blog!</subtitle>
  <link href="https://nobodyyj.github.io/atom.xml" rel="self"/>
  
  <link href="https://nobodyyj.github.io/"/>
  <updated>2025-07-30T15:04:56.989Z</updated>
  <id>https://nobodyyj.github.io/</id>
  
  <author>
    <name>Huang Yujie</name>
    <email>struggle_hyj@outlook.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>2025年中总结</title>
    <link href="https://nobodyyj.github.io/post/480016f9.html"/>
    <id>https://nobodyyj.github.io/post/480016f9.html</id>
    <published>2025-07-30T14:16:16.000Z</published>
    <updated>2025-07-30T15:04:56.989Z</updated>
    
    <content type="html"><![CDATA[<p>今天趁着台风“竹节草”登陆上海，公司放了半天台风假，得以忙里偷闲记录对最近这几个月的实习做一个阶段性总结。</p><p>在lq的两个多月是我目前距离行业top公司最近的一段经历，做的方向大体上有一定深度，是关于高频特征的构造与截面日间因子的挖掘，方向倒是挺有意思的，但是和带教相处的氛围与沟通的模式实在是让我无法忍受。我觉得在这家公司收获到的最重要的经验，就是如何开展某一个细分领域的研究，构筑自己的个人核心竞争力。</p><p>首要的就是摆正心态，做研究一定是会遇到失败的。但是除了记下“这个方向做不了”这个结论，具体研究的过程与思路同样值得记录，每次失败做记录时要具体到出发点、研究方法。举个例子，在研究“高频量价相关性”的时候，直接用Pearson相关系数计算高频数据的量价相关性是效果很差的，但是对重采样后、按price变动方向划分后的数据，对数据做完cox-box变换后的pearson相关系数可能就是有效的。记录失败的研究经历不止是为了避免未来重复无效做无效实验，在失败样本多了之后，可以通过总结与提取失败经历的共通特征找到正确的灵感和市场直觉。这种灵光一现的想法对提高个人核心竞争力（其实就是对市场的独特理解、有自己独有的策略）非常有帮助。</p><p>6月底，我又回到了lh。目前干了一个多月，还是不确定到底能不能拿到returnoffer。不过在和mentor聊天的过程中我对这个行业有了新的认知。拿到returnoffer也不代表入行，这个行业真正的入行门槛是个人做出可以赚到钱的策略。这个策略开发的难度与盈利能力并非正相关，而与市场观察与理解高度相关。比如我现在在做的方向，我很明确的知道挣不到消息面驱动下市场快速反应的钱，但是这个反而是我手工交易可以做到的。</p><p>给自己加个油，多学习，多尝试，多记录，多总结。不要害怕有意义的失败，也不要欣喜于无法解释的成功。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;今天趁着台风“竹节草”登陆上海，公司放了半天台风假，得以忙里偷闲记录对最近这几个月的实习做一个阶段性总结。&lt;/p&gt;
&lt;p&gt;在lq的两个多月是我目前距离行业top公司最近的一段经历，做的方向大体上有一定深度，是关于高频特征的构造与截面日间因子的挖掘，方向倒是挺有意思的，但是</summary>
      
    
    
    
    <category term="阶段性总结" scheme="https://nobodyyj.github.io/categories/%E9%98%B6%E6%AE%B5%E6%80%A7%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="实习" scheme="https://nobodyyj.github.io/tags/%E5%AE%9E%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>2024年度回顾</title>
    <link href="https://nobodyyj.github.io/post/3beb882d.html"/>
    <id>https://nobodyyj.github.io/post/3beb882d.html</id>
    <published>2024-12-31T15:54:47.000Z</published>
    <updated>2024-12-31T15:55:18.496Z</updated>
    
    <content type="html"><![CDATA[<p>2024年应该是目前为止我人生中最重要的一年。</p><p>1月，结束了第一段量化领域的实习，懵懵懂懂地开始了数字货币投资，正好赶上牛市前夕。</p><p>2月，过年，随着比特币冲击前高6w7后的插针，人生中第一次经历爆仓，三十倍收益一夜归0。</p><p>3月，一边捣鼓量化交易在数字货币市场的应用，一边海投各家私募。9号收到第二段量化实习的实习offer，因为工资足够在上海生活而不是生存激动了一下午。</p><p>4月，正式入职，同时开启陆家嘴金融鼠鼠&amp;研0的体验卡——白天上班夜里上课。因为无法同时兼顾学业与职业发展，萌生退学的想法。卡着ddl递交了gzs的申请。</p><p>5月，和同事们一起去欢乐谷团建，成功确诊“过山车绝缘体质”。晚上的课程开始跟不上，每次学校考试前疯狂失眠。</p><p>6月，和npy去了上海迪士尼，完成了人生一大心愿。回校参加毕业典礼，彻底告别本科。</p><p>7月，开始远程办公，综合再三决定放弃入学，交了gzs的留位费。与此同时，数字货币策略开始实盘，体验了一把PM的感受。</p><p>8月，和好朋友一起去了韩国旅游，填补了没有毕业旅行的遗憾。成功涨薪。</p><p>9月，入学gzs，一边上课一边实习，基本一整个月都忙着调参。</p><p>10月， 苟过了midterm，周末在深圳疯狂觅食，这个月时间过得好快。</p><p>11月，all inTrump胜选，通了好几个宵，靠着DOGE收回了年初的所有亏损，捐出了人生中第一笔钱。</p><p>12月，补天复习final，得知returnoffer不一定能顺利拿到，感慨量化行业的残酷，重新捡起数字货币自营策略。</p><p>回顾2024，我做了很多很疯狂的选择，我不清楚若干年后的我会如何评价今年的选择，但是我相信从拓展人生体验感的角度出发我没有浪费这一年。希望2025能继续追寻我的梦想。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;2024年应该是目前为止我人生中最重要的一年。&lt;/p&gt;
&lt;p&gt;1月，结束了第一段量化领域的实习，懵懵懂懂地开始了数字货币投资，正好赶上牛市前夕。&lt;/p&gt;
&lt;p&gt;2月，过年，随着比特币冲击前高6w7后的插针，人生中第一次经历爆仓，三十倍收益一夜归0。&lt;/p&gt;
&lt;p&gt;3月</summary>
      
    
    
    
    <category term="日常随笔" scheme="https://nobodyyj.github.io/categories/%E6%97%A5%E5%B8%B8%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="年度总结" scheme="https://nobodyyj.github.io/tags/%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>数字货币截面回测框架</title>
    <link href="https://nobodyyj.github.io/post/1a7af3c0.html"/>
    <id>https://nobodyyj.github.io/post/1a7af3c0.html</id>
    <published>2024-12-03T07:43:40.000Z</published>
    <updated>2025-01-05T09:41:37.596Z</updated>
    
    <content type="html"><![CDATA[<h1 id="motivation">Motivation</h1><p>最近在数字货币市场主观投资收益反反复复，实在是有些顶不住了，加之复习周无聊，心血来潮想开个项目记录一下自己重构数字货币的截面回测框架的过程。</p><p>暂时的思维导图是</p><ol type="1"><li>构建格式化标准数据。具体标准参考<code>asim_io</code></li><li>使用格式化数据进行向量化回测</li></ol><p>改进方案:</p><p>使用rust or C++ 对alpha values 作事件驱动型回测。</p><h1 id="项目进度">项目进度:</h1><h2 id="section">2024-12-3</h2><p>重构build数据的代码。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;motivation&quot;&gt;Motivation&lt;/h1&gt;
&lt;p&gt;最近在数字货币市场主观投资收益反反复复，实在是有些顶不住了，加之复习周无聊，心血来潮想开个项目记录一下自己重构数字货币的截面回测框架的过程。&lt;/p&gt;
&lt;p&gt;暂时的思维导图是&lt;/p&gt;
&lt;ol typ</summary>
      
    
    
    
    <category term="自营" scheme="https://nobodyyj.github.io/categories/%E8%87%AA%E8%90%A5/"/>
    
    
    <category term="量化" scheme="https://nobodyyj.github.io/tags/%E9%87%8F%E5%8C%96/"/>
    
    <category term="数字货币" scheme="https://nobodyyj.github.io/tags/%E6%95%B0%E5%AD%97%E8%B4%A7%E5%B8%81/"/>
    
  </entry>
  
  <entry>
    <title>2024-11 随笔</title>
    <link href="https://nobodyyj.github.io/post/bf520371.html"/>
    <id>https://nobodyyj.github.io/post/bf520371.html</id>
    <published>2024-11-17T12:50:23.000Z</published>
    <updated>2024-12-29T14:06:21.058Z</updated>
    
    <content type="html"><![CDATA[<p>​    今天是2024-11-17，距离我第一次在xytz进行量化实习已经一年多了，距离我进入lhzc实习也有7个多月了，临近final请了一个月长假，也算是终于有时间写一写目前我的一些想法与感受。既是为了对这一年多的实习经历做一个阶段性总结，也是为了与未来的我对话给我一些新的思考。</p><p>​    股票方面，我掌握了从wind推送的原始数据构建三维财务报表的方法，重构了公司的基本面数据库，但是在真正使用的时候仍然卡在“如何将基本面与量价因子结合”上，之前茂源的pm说“为了用好的价格买到好的公司”，我觉得是一句非常精妙的总结。写因子的时候我还是会要东抄抄西抄抄，看paper看研报，我潜意识觉得可能还是需要展开自己的研究，至少需要培养自己展开研究的能力并养成这种习惯，但是目前明显双线程的我没有这种闲情雅致（以后会有的吧）。。我做的K线图识别模型马上就要实盘了，看起来到24年9月底的效果都还不错，希望OS能好到让我留用，不然就得继续重复枯燥无味的训练了</p><p>​    数字货币方面，今年九月之前一直在忙着和quantgroup的朋友们完善统计套利策略，但是其实从下单算法、止损止盈上都还有很大的优化空间，上学以后没有继续推进真的非常可惜。不过总算是有了实盘的策略，过了一把PM的瘾。随着特朗普上台，我觉得数字货币会具有越来越大的流动性，未来应该要花时间在上面完善时序策略与截面策略，早日做到A7甚至A8的水平。</p><p>​    这一年来的实习让我对这个行业彻底祛魅了，但是在看清行业本质以后，我更加确信了这是我愿意花时间花精力投入的行业，希望我能继续保持对研究市场的热爱，保持对探寻市场规律的着迷。同时也能保持自己“与死亡抗争”而学习工作的初心。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;​    今天是2024-11-17，距离我第一次在xytz进行量化实习已经一年多了，距离我进入lhzc实习也有7个多月了，临近final请了一个月长假，也算是终于有时间写一写目前我的一些想法与感受。既是为了对这一年多的实习经历做一个阶段性总结，也是为了与未来的我对话给我一</summary>
      
    
    
    
    <category term="日常随笔" scheme="https://nobodyyj.github.io/categories/%E6%97%A5%E5%B8%B8%E9%9A%8F%E7%AC%94/"/>
    
    
    <category term="量化" scheme="https://nobodyyj.github.io/tags/%E9%87%8F%E5%8C%96/"/>
    
    <category term="随笔" scheme="https://nobodyyj.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>CNN识别K线图</title>
    <link href="https://nobodyyj.github.io/post/9f0434dc.html"/>
    <id>https://nobodyyj.github.io/post/9f0434dc.html</id>
    <published>2024-04-23T08:22:58.000Z</published>
    <updated>2024-09-22T12:48:22.748Z</updated>
    
    <content type="html"><![CDATA[<h1 id="alexnet识别k线">1.AlexNet识别K线</h1><h2 id="模型的结构">模型的结构</h2><p><img src="/post/9f0434dc/image-20240423161730775.png"></p><h2 id="code">Code</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">from</span> torch <span class="token keyword">import</span> nnnet <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>    <span class="token comment"># 这里使用一个11*11的更大窗口来捕捉对象。</span>    <span class="token comment"># 同时，步幅为4，以减少输出的高度和宽度。</span>    <span class="token comment"># 另外，输出通道的数目远大于LeNet</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">96</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">11</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment"># 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">96</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment"># 使用三个连续的卷积层和较小的卷积窗口。</span>    <span class="token comment"># 除了最后的卷积层，输出通道的数量进一步增加。</span>    <span class="token comment"># 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment"># 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">6400</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span> nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>    <span class="token comment"># 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000</span>    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="paper">2.Paper</h1><p><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3756587">JIANG,J., KELLY, B. and XIU, D. (2023), (Re-)Imag(in)ing Price Trends. JFinance, 78: 3193-3249.</a></p><h3 id="abstract">Abstract</h3><p>我们重新考虑了基于趋势的可预测性的想法，使用的方法是灵活学习最能预测未来回报的价格模式，而不是测试假设的或预先指定的模式（例如，动量和反转）。我们的原始预测数据是图像——股票级别的价格图表——我们使用机器学习图像分析方法从中诱导出最佳预测回报的价格模式。我们识别出的预测模式与文献中常分析的趋势信号大不相同，它们提供了更准确的回报预测，转化为更有利可图的投资策略，并且对一系列规范变化具有鲁棒性。这些模式还表现出与环境无关的特性：在短时间尺度（例如，日常数据）估计的预测模式，当应用于更长的时间尺度（例如，月度）时，同样能给出强有力的预测，从美国股市学到的模式在国际市场上同样能够很好地预测。</p><h2 id="原论文的input-data">2.1 原论文的input data</h2><p><strong>数据集：</strong>CRSP数据库中纽约证券交易所（NYSE）、美国证券交易所（AMEX）和纳斯达克（NASDAQ）上市的所有公司的每日股票数据。包括每日开盘价、最高价、最低价和调整后的收盘价。</p><p><strong>数据集区间：</strong> 从1993年至2019年。</p><p><strong>时间长度：</strong> 数据覆盖了27年的股市交易数据。</p><p><strong>数据使用细节：</strong></p><ul><li><strong>价格调整：</strong>第一天的收盘价标准化为1，后续每天的收盘价根据日收益率计算。</li><li><strong>标签定义：</strong>使用过去5天、20天或60天的市场数据图像，标签基于图像后的5天、20天或60天内的收益率是正还是非正。</li></ul><p><strong>训练和测试细节：</strong></p><ul><li><strong>数据划分：</strong>1993年至2000年的数据用于训练和验证（70%训练，30%验证），2001年至2019年的数据用作固定测试集。</li><li><strong>模型训练：</strong>采用CNN模型，每种模型配置独立训练五次并平均预测结果。</li></ul><blockquote><p>We use daily stock data from CRSP for all firms listed on NYSE, AMEX,and NASDAQ. Our sample runs from 1993–2019 based on the fact that dailyopening, high, and low prices first become available in June 1992. Ourprice trend analysis focuses on returns adjusted for corporate actionsby using returnsto construct a price series. In each image, we normalizethe first day closing price to one, and construct each subsequent dailyclose from returns (RETt) according to</p><p><span class="math display">\[p_{t+1}=\left(1+R E T_{t+1}\right) p_t\]</span> Each day’s opening/high/low price levels are scaled inproportion to that day’s closing price level.</p><p>We consider three input choices that include images of market dataover the past 5, 20, or 60 days. Image labels take a value of one orzero for positive or non-positive returns over the 5, 20, or 60 dayssubsequent to the image. Thus, our main analysis amounts to nineseparately estimated models. Because the CNN optimization is stochastic,for each model configuration we independently re-train the CNN fivetimes and average their forecasts (following Gu et al., 2020).</p><p>Two important considerations when reading our empirical results arethat we do not recursively re-train the model and that we randomlyselect training and validation samples. Specifically, we train andvalidate each model only once using data from 1993 to 2000, in which 70%of the sample are randomly selected for training and the remaining 30%for validation. The trained CNN model is then held fixed for the entire2001 to 2019 test sample. This design is primarily due to capacity incomputational resources. Adopting a rolling window and repeatedlyretraining is likely to further improve the predictions.</p><p>Every period in which we construct new forecasts (weekly, monthly, orquarterly, depending on the model’s forecast horizon), we sort stocksinto decile portfolios based on out-of-sample CNN estimates forprobability of a positive subsequent return. We also construct along-short spread portfolio (“H-L”) that is long decile 10 and shortdecile 1. The holding period for each portfolio coincides with theforecast horizon for each model (either 5, 20, or 60 days following thelast date in an image). Throughout we use the notation “Ix/Ry” to denotethat the model uses x-day images to predict subsequent y-day holdingperiod returns.</p></blockquote><h2 id="train-方法">2.2 train 方法</h2><p>我们从训练到模型调整，最后到预测的工作流程遵循 Gu et al.(2020)概述的基本程序。首先，我们将整个样本分为训练样本、验证样本和测试样本。在我们的主要美国数据样本中，我们在样本开始时使用单个八年样本（1993-2000）来估计和验证模型。在这个八年样本中，我们随机选择70% 的图像进行训练，30%的图像进行验证。随机选择训练和验证样本有助于平衡分类问题中的正标签和负标签，从而减轻由于长期看涨或看跌市场波动而导致的分类潜在偏差。在我们考虑的所有场景中，生成的训练和验证图像的标签大约有50% 向上和 50%向下。剩余十九年（2001-2019）的数据构成样本外测试数据集。</p><h3 id="loss-function">Loss Function</h3><p><span class="math display">\[L(y, \hat{y})=-y \log (\hat{y})-(1-y) \log (1-\hat{y})\]</span></p><h3 id="hyperparameters">Hyperparameters</h3><ol type="1"><li><strong>初始权重分布</strong>：使用Xavier初始化器（Glorot andBengio,2010）设置每层的权重初始值，以确保预测的方差与标签的方差开始时处于相似的规模。</li><li><strong>学习率</strong>：在使用随机梯度下降和Adam算法（Kinga andAdam, 2015）进行损失函数优化时，初始学习率设为1 × 10^-5。</li><li><strong>批量大小</strong>：批量大小设为128。</li><li><strong>批量正规化</strong>：在每个构建块中的卷积层和非线性激活层之间使用批量正规化层（Ioffeand Szegedy, 2015），以减少协变量偏移。</li><li><strong>Dropout率</strong>：在全连接层应用50%的dropout（Srivastavaet al., 2014），以减少过拟合。</li><li><strong>早停机制</strong>：使用早停（earlystopping）策略，在验证样本的损失函数连续两个训练周期不再改善时停止训练。</li></ol><blockquote><p>We adopt the same regularization procedures in Gu et al. (2020) tocombat overfit and aid efficient computation. We apply the Xavierinitializer for weights in each layer (Glorot and Bengio, 2010). Thispromotes faster convergence by generating starting values for weights toensure that prediction variance begins on a comparable scale to that ofthe labels. Loss function optimization uses stochastic gradient descentand the Adam algorithm (Kinga and Adam, 2015) with initial learning rateof 1 × 10−5 and batch size of 128. We use a batch normalization (Ioffeand Szegedy, 2015) layer between the convolution and non-linearactivation within each building block to reduce covariate shift.7 Weapply 50% dropout (Srivastava et al., 2014) to the fully connected layer(the relatively low parameterization in convolutional blocks avoids theneed for dropout there). Finally, we use early stopping to halt trainingonce the validation sample loss function fails to improve for twoconsecutive epochs. Gu et al. (2020) outline the intuition behind thesechoices, so for the sake of brevity, we omit this discussion and insteadrefer interested readers there.</p></blockquote><h1 id="广发-安宁宁">3.广发 安宁宁</h1><h3 id="input-data">1.input data</h3><p>要自己生成，可以自己加入技术指标、OHLC价格、Volume等。但是可能会数据量很大。</p><h3 id="模式的structure可以按照alexnet-or-安宁宁的">2.模式的structure可以按照alexnetor 安宁宁的</h3><table><colgroup><col style="width: 50%"><col style="width: 50%"></colgroup><thead><tr class="header"><th style="text-align: center;">AlexNet</th><th style="text-align: center;">安宁宁</th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><img src="/post/9f0434dc/image-20240423161730775.png"></td><td style="text-align: center;"><img src="/post/9f0434dc/image-20240423161801443.png"></td></tr></tbody></table><h3 id="output">3.output</h3><p>模型的最终输出为3个概率，分别对应个股在未来截面日上收益率的百分位，即后1/3、中1/3、前1/3，以表示跌、平、涨。最终以股票上涨的概率作为因子进行选股。</p><p><strong>也许可以对收益率分箱，进行更多分类，转化为预测涨跌幅度而非概率。</strong></p><h2 id="原文">原文：</h2><blockquote><p><img src="/post/9f0434dc/image-20240423160948219.png"></p><p><img src="/post/9f0434dc/image-20240423161005878.png"></p><p><img src="/post/9f0434dc/image-20240423161040743.png"></p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;alexnet识别k线&quot;&gt;1.AlexNet识别K线&lt;/h1&gt;
&lt;h2 id=&quot;模型的结构&quot;&gt;模型的结构&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/post/9f0434dc/image-20240423161730775.png&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;c</summary>
      
    
    
    
    
    <category term="机器学习" scheme="https://nobodyyj.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="CNN" scheme="https://nobodyyj.github.io/tags/CNN/"/>
    
  </entry>
  
  <entry>
    <title>统计学习 学习记录</title>
    <link href="https://nobodyyj.github.io/post/e5e13074.html"/>
    <id>https://nobodyyj.github.io/post/e5e13074.html</id>
    <published>2024-02-21T11:30:58.000Z</published>
    <updated>2024-12-29T14:09:20.985Z</updated>
    
    <content type="html"><![CDATA[<p>作为非科班出身的金数人，在学习机器学习模型时我发现自对一些最基础、最本质的概念理解不够深入，所以打算写一篇blog，记录一下自己在学习的时候遇到的零零散散的问题。</p><h2 id="极大似然估计mle和损失函数的关系">1.极大似然估计(MLE)和损失函数的关系</h2><ol type="1"><li>若变量服从高斯分布，MLE的结果是OLS</li><li>若变量服从伯努利分布，MLE的结果是logistic回归</li><li>若变量服从多项式分布，MLE的结果是softmax</li></ol><h2 id="当我们对损失函数正则化时我们在做什么">2.当我们对损失函数正则化时，我们在做什么？</h2><p>做正则化的目的就是为了提高训练出模型的泛化能力。影s响模型泛化能力的是权重<span class="math inline">\(w\)</span> 和偏置 <span class="math inline">\(b\)</span> 。</p><p>参考：<a href="https://www.bilibili.com/video/BV1Z44y147xA/?spm_id_from=333.337.search-card.all.click&amp;vd_source=44ba9a7b92cb9c058705d88870afca92">“L1和L2正则化”直观理解</a></p><h3 id="拉格朗日对偶角度">2.1 拉格朗日对偶角度</h3><p>所谓正则化，就是在损失函数中加上Lp范数。</p><p><img src="/post/e5e13074/image-20240221221538595.png"></p><blockquote><p>为什么说L1正则化（右）可以带来稀疏性，就是因为L1正则化后的极值点容易出现在坐标轴上，而出现在坐标轴上意味着其他某些维度的值为0，比如要用胡子和毛色区分猫咪和狗，L2正则化（左）可能只是赋予两个特征不同的权重，<span class="math inline">\(\lambda\)</span>​的作用是来调节权重大小，而L1正则化就可能只考虑胡子，而不考虑毛色，这就带来了<strong>稀疏性</strong>。·+<span class="math inline">\(x\)</span>是训练集里面的数据，视作常数不考虑；真正决定拟合效果的是权重<span class="math inline">\(W\)</span>，所以偏置<span class="math inline">\(b\)</span>虽然是未知参数也不进行研究； <span class="math display">\[\|W\|_1-C \leq \mathbf{0}\]</span> 这里可以理解为只考虑对<span class="math inline">\(W\)</span>的可行域范围进行约束 。</p></blockquote><blockquote><figure><img src="/post/e5e13074/image-20240224212331595.png" alt="Lp范数的可视化"><figcaption aria-hidden="true">Lp范数的可视化</figcaption></figure><p>只有p&gt;=1的时候，Lp范数才是一个凸集，这时候以Lp范数作为约束的问题才能是一个凸优化问题；反之，若0&lt;p&lt;1，集合就是非凸集。</p></blockquote><p><strong>我们看到的L2正则化的函数和原问题的拉格朗日函数之间的关系</strong></p><p><img src="/post/e5e13074/image-20240224213614031.png"></p><p>在这个问题中，红的的函数与绿色相比，少了一个<span class="math inline">\(\lambda\)</span><span class="math inline">\(C\)</span>，这个C其实调节的是圆半径的大小，在绿色函数中，就是C视为已知，来求<span class="math inline">\(\lambda\)</span>；而在红色函数中，是用<span class="math inline">\(\lambda\)</span>来调节圆的半径，每一个极值点都对应一对共线相反大小相等的梯度，对应一个特别的<span class="math inline">\(\lambda\)</span>，也就是对应一个半径C（即可以通过调节<span class="math inline">\(\lambda\)</span>来调节<span class="math inline">\(C\)</span>。</p><p>红色和绿色两个函数对<span class="math inline">\(W\)</span>求梯度后，得到的W值是相等的，因为<span class="math inline">\(\lambda\)</span><span class="math inline">\(C\)</span>在对<span class="math inline">\(W\)</span>求导的时候为0。看似这两个问题是等价的，但是其实超参数已经改变了，上面的超参数是<span class="math inline">\(C\)</span>，下面的是<span class="math inline">\(\lambda\)</span>。</p><p><strong>L1正则化和L2正则化的特性</strong>：</p><p>L1正则化会带来稀疏性。（待补充）</p><p><img src="/post/e5e13074/image-20240221223742439.png"></p><blockquote><p>为什么说L1正则化（右）可以带来稀疏性，就是因为L1正则化后的极值点容易出现在坐标轴上，而出现在坐标轴上意味着其他某些维度的值为0，比如要用胡子和毛色区分猫咪和狗，L2正则化（左）可能只是赋予两个特征不同的权重，<span class="math inline">\(\lambda\)</span>的作用是来调节权重大小，而L1正则化就可能只考虑胡子，而不考虑毛色，这就带来了<strong>稀疏性</strong>。</p></blockquote><h2 id="树模型">3.树模型</h2><h3 id="基础的树">3.1 基础的树</h3><p>李航统计学习上比较基础的树模型：ID3 C4.5 CART</p><p>三者区别：</p><ul><li><strong>划分标准的差异：</strong>ID3使用信息增益偏向特征值多的特征，C4.5使用信息增益率克服信息增益的缺点，偏向于特征值小的特征，CART使用基尼指数克服 C4.5 需要求 log的巨大计算量，偏向于特征值较多的特征。</li><li><strong>使用场景的差异：</strong>ID3 和 C4.5都只能用于分类问题，CART 可以用于分类和回归问题；ID3 和 C4.5是多叉树，速度较慢，CART 是二叉树，计算速度很快；</li><li><strong>样本数据的差异：</strong>ID3只能处理离散数据且缺失值敏感，C4.5 和 CART可以处理连续性数据且有多种方式处理缺失值；从样本量考虑的话，小样本建议C4.5、大样本建议 CART。C4.5处理过程中需对数据集进行多次扫描排序，处理成本耗时较高，而 CART本身是一种大样本的统计方法，小样本处理下泛化误差较大 ；</li><li><strong>样本特征的差异：</strong>ID3 和 C4.5层级之间只使用一次特征，CART 可多次重复使用特征；</li><li><strong>剪枝策略的差异：</strong>ID3 没有剪枝策略，C4.5是通过悲观剪枝策略来修正树的准确性，而 CART 是通过代价复杂度剪枝。</li></ul><h3 id="基于集成学习的改进">3.2 基于集成学习的改进</h3><p><strong>基于Bagging算法典型代表</strong></p><p>随机森林（Random Forest）</p><p><strong>基于Boosting算法典型代表</strong></p><p>如AdaBoost、GBDT、XGBoost等。</p><blockquote><p>1）Bagging + 决策树 = 随机森林</p><p>2）AdaBoost + 决策树 = 提升树</p><p>3）Gradient Boosting + 决策树 = GBDT</p></blockquote><p><strong>那么Bagging和Boosting的区别是什么呢？</strong></p><p>1）样本选择：</p><p>Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。</p><p>Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。</p><p><strong>基于这个性质我们可以知道，Bagging后的bias与单模型接近，而variance能显著下降，每个基模型之间是独立的。</strong></p><p>2）样例权重：</p><p>Bagging：使用均匀取样，每个样例的权重相等</p><p>Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。</p><p>3）预测函数：</p><p>Bagging：所有预测函数的权重相等。</p><p>Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。</p><p>4）并行计算：</p><p>Bagging：各个预测函数可以并行生成</p><p>Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。</p><p>5）适用场景：</p><p>Bagging: High Variance &amp; Low Bias</p><p>Boosting: Low Variance &amp; High Bias</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;作为非科班出身的金数人，在学习机器学习模型时我发现自对一些最基础、最本质的概念理解不够深入，所以打算写一篇blog，记录一下自己在学习的时候遇到的零零散散的问题。&lt;/p&gt;
&lt;h2 id=&quot;极大似然估计mle和损失函数的关系&quot;&gt;1.极大似然估计(MLE)和损失函数的关系&lt;/</summary>
      
    
    
    
    <category term="学习记录" scheme="https://nobodyyj.github.io/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
    
    
    <category term="机器学习" scheme="https://nobodyyj.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>从零开始在vscode上配置C++运行环境</title>
    <link href="https://nobodyyj.github.io/post/d38d0dd6.html"/>
    <id>https://nobodyyj.github.io/post/d38d0dd6.html</id>
    <published>2024-02-06T11:55:40.000Z</published>
    <updated>2024-02-18T02:37:49.814Z</updated>
    
    <content type="html"><![CDATA[<h1 id="从零开始在vscode上配置c运行环境">从零开始在vscode上配置C++运行环境</h1><p>​本文用于记录我在配置C++时遇到的坑。之前在配置的时候是花钱找tb帮忙做的，这次打算记录下来这个过程，以便后续复现。</p><h2 id="安装mingw编译器">1.安装MinGW编译器</h2><p>​ 需要从<a href="https://sourceforge.net/projects/mingw-w64/files/mingw-w64/mingw-w64-release/">SourceForge.net</a>处下载MinGW编译器.</p><h3 id="选择合适的版本">1.1 选择合适的版本</h3><figure><img src="/post/d38d0dd6/image-20240206200640071.png" alt="image-20240206200640071"><figcaption aria-hidden="true">image-20240206200640071</figcaption></figure><figure><img src="/post/d38d0dd6/v2-2d0276533469f23e148dbe7b8e688b85_720w.png" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><h3 id="配置系统环境">1.2 配置系统环境</h3><p>将（比如我的是D:_64-8.1.0-release-posix-seh-rt_v6-rev0）添加入电脑系统环境<img src="https://pic1.zhimg.com/80/v2-aa4899ab623657407ad5dca167a5bf80_720w.webp" alt="img"></p><figure><img src="/post/d38d0dd6/image-20240206201139096.png" alt="image-20240206201139096"><figcaption aria-hidden="true">image-20240206201139096</figcaption></figure><h3 id="验证是否成功安装">1.3 验证是否成功安装</h3><p>打开cmd，输入<code>gcc -v</code></p><figure><img src="/post/d38d0dd6/image-20240206201212569.png" alt="image-20240206201212569"><figcaption aria-hidden="true">image-20240206201212569</figcaption></figure><p>出现上述内容说明安装成功</p><h2 id="在vscode中安装cc插件">2.在vscode中安装C/C++插件</h2><figure><img src="/post/d38d0dd6/image-20240206200423060.png" alt="image-20240206200423060"><figcaption aria-hidden="true">image-20240206200423060</figcaption></figure><h2 id="配置cc环境">3.配置C/C++环境</h2><figure><img src="/post/d38d0dd6/v2-0b4821eecf84239ddd2cb1770e6520c3_720w.png" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>可以先建立 .vscode文件夹</p><h3 id="配置编译器">3.1 配置编译器</h3><p><strong>（在.vscode文件夹含有c_cpp_properties.json文件）</strong></p><p>首先按快捷键Ctrl+Shift+P调出命令面板，输入C/C++，选择“EditConfigurations(UI)”进入配置。</p><p>接着这里配置两个选项： - 编译器路径：</p><pre class="line-numbers language-text" data-language="text"><code class="language-text">D:/mingw-w64/x86_64-8.1.0-win32-seh-rt_v6-rev0/mingw64/bin/g++.exe<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>这里的路径根据大家自己安装的Mingw编译器位置和配置的环境变量位置所决定。</p><figure><img src="/post/d38d0dd6/v2-6c92ebccb5ee908a85aaf00e6b266c87_720w.webp" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>第一步</p><figure><img src="/post/d38d0dd6/v2-30f3dbb1578b72af40fb646ec57c08fb_720w.webp" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>第二步</p><figure><img src="/post/d38d0dd6/v2-da4e9d35e8e9dadb8b1ed1a64f7a9f90_720w.webp" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>第三步</p><p>配置完成后，此时在侧边栏可以发现多了一个.vscode文件夹，并且里面有一个c_cpp_properties.json文件，内容如下，说明上述配置成功。现在可以通过**Ctrl+<code>快捷键**打开内置终端并进行编译运行了。（ESC下边的</code>）</p><p><strong>c_cpp_properties.json</strong></p><pre class="line-numbers language-jsonld" data-language="jsonld"><code class="language-jsonld">&#123;    &quot;configurations&quot;: [        &#123;            &quot;name&quot;: &quot;Win32&quot;,            &quot;includePath&quot;: [                &quot;$&#123;workspaceFolder&#125;&#x2F;**&quot;            ],            &quot;defines&quot;: [                &quot;_DEBUG&quot;,                &quot;UNICODE&quot;,                &quot;_UNICODE&quot;            ],            &quot;windowsSdkVersion&quot;: &quot;10.0.17763.0&quot;,            &quot;compilerPath&quot;: &quot;C:\\Program Files\\mingw64\\bin\\gcc.exe&quot;,            &quot;cStandard&quot;: &quot;c17&quot;,            &quot;cppStandard&quot;: &quot;c++17&quot;,            &quot;intelliSenseMode&quot;: &quot;gcc-x64&quot;        &#125;    ],    &quot;version&quot;: 4&#125;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="配置构建任务">3.2 配置构建任务</h3><p><strong>（在.vscode文件夹中创建一个tasks.json文件）</strong></p><p>该任务将调用g++编译器基于源代码创建可执行文件。按快捷键Ctrl+Shift+P调出命令面板，输入tasks，选择“Tasks:ConfigureDefault Build Task”：</p><figure><img src="/post/d38d0dd6/v2-4c31d3e823dc3e51e44886380484fce2_720w.png" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>第一步哟</p><p>再选择“C/C++: g++.exe build active file”：</p><figure><img src="/post/d38d0dd6/v2-3836bdbba135f75567e4f0b72b57e5a2_720w.png" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>第二步呀</p><p>此时会出现一个名为tasks.json的配置文件，内容如下：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>    <span class="token comment">// See https://go.microsoft.com/fwlink/?LinkId=733558 </span>    <span class="token comment">// for the documentation about the tasks.json format</span>    <span class="token property">"tasks"</span><span class="token operator">:</span> <span class="token punctuation">[</span>        <span class="token punctuation">&#123;</span><span class="token comment">//构建配置项</span>            <span class="token property">"type"</span><span class="token operator">:</span><span class="token string">"shell"</span><span class="token punctuation">,</span><span class="token comment">//任务类型,Vscode将预定义变量转义解析后直接传给command;shell->先打开shell再输入命令,因此args会经过shell再次解析</span>            <span class="token property">"label"</span><span class="token operator">:</span> <span class="token string">" "</span>g++.exe build active file<span class="token string">""</span><span class="token punctuation">,</span><span class="token comment">//任务名称</span>            <span class="token property">"command"</span><span class="token operator">:</span> <span class="token string">"C:\\Program Files\\mingw64\\bin\\gcc.exe"</span><span class="token punctuation">,</span><span class="token comment">//记得修改本地编译器路径</span>            <span class="token property">"args"</span><span class="token operator">:</span> <span class="token punctuation">[</span> <span class="token comment">//包含传给gcc命令的参数,用于实现特定功能</span>                <span class="token string">"-g"</span><span class="token punctuation">,</span> <span class="token comment">//生成和调试有关的信息</span>                <span class="token string">"$&#123;file&#125;"</span><span class="token punctuation">,</span> <span class="token comment">//指定编译文件为当前文件</span>                <span class="token string">"-o"</span><span class="token punctuation">,</span><span class="token comment">//指定输出文件的路径和名称</span>                <span class="token comment">//"$&#123;fileDirname&#125;\\$&#123;fileBasenameNoExtension&#125;.exe"</span>                <span class="token string">"$&#123;workspaceFolder&#125;\\build\\$&#123;fileBasenameNoExtension&#125;.exe"</span><span class="token comment">//修改.exe文件生成位置</span>            <span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token property">"options"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span>                <span class="token comment">//"cwd": "$&#123;fileDirname&#125;"</span>                <span class="token property">"cwd"</span><span class="token operator">:</span> <span class="token string">"C:\\Program Files\\mingw64\\bin"</span>            <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>            <span class="token property">"problemMatcher"</span><span class="token operator">:</span> <span class="token punctuation">[</span>                <span class="token string">"$gcc"</span>            <span class="token punctuation">]</span><span class="token punctuation">,</span>            <span class="token property">"group"</span><span class="token operator">:</span> <span class="token punctuation">&#123;</span><span class="token comment">//包含很多task,归为group</span>                <span class="token property">"kind"</span><span class="token operator">:</span> <span class="token string">"build"</span><span class="token punctuation">,</span><span class="token comment">//表名该组任务类型是构建</span>                <span class="token property">"isDefault"</span><span class="token operator">:</span> <span class="token boolean">true</span><span class="token comment">//表明此任务为此组任务中的默认任务</span>            <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>            <span class="token property">"detail"</span><span class="token operator">:</span> <span class="token string">"调试器生成的任务。"</span>        <span class="token punctuation">&#125;</span>    <span class="token punctuation">]</span><span class="token punctuation">,</span>    <span class="token property">"version"</span><span class="token operator">:</span> <span class="token string">"2.0.0"</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><figure><img src="/post/d38d0dd6/v2-113ac7497af63217711d42d1b8ef1cda_720w.webp" alt="img"><figcaption aria-hidden="true">img</figcaption></figure><p>可以参考一下</p><p>（本部分参考：<a href="https://zhuanlan.zhihu.com/p/545908287">【详细版】VsCode搭建C++环境- 知乎 (zhihu.com)</a>）</p><hr><p><strong>此时，已经可以正常运行和调试.cpp的文件了！</strong></p><figure><img src="/post/d38d0dd6/image-20240206203324701.png" alt="image-20240206203324701"><figcaption aria-hidden="true">image-20240206203324701</figcaption></figure><p>但是此时编译好的.exe后缀文件会保存在原代码的位置，看起来非常的丑！</p><figure><img src="/post/d38d0dd6/image-20240206203445574.png" alt="image-20240206203445574"><figcaption aria-hidden="true">image-20240206203445574</figcaption></figure><p>我们希望把.exe文件放到bin文件夹中</p><h3 id="设置输出编译后文件至某一文件夹">3.3设置输出编译后文件至某一文件夹</h3><figure><img src="/post/d38d0dd6/image-20240206203843473.png" alt="image-20240206203843473"><figcaption aria-hidden="true">image-20240206203843473</figcaption></figure><p>把这一行代码的输出改为如图所示。</p><figure><img src="/post/d38d0dd6/image-20240206203904210.png" alt="image-20240206203904210"><figcaption aria-hidden="true">image-20240206203904210</figcaption></figure><p><strong>成功！</strong></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;从零开始在vscode上配置c运行环境&quot;&gt;从零开始在vscode上配置C++运行环境&lt;/h1&gt;
&lt;p&gt;​
本文用于记录我在配置C++时遇到的坑。之前在配置的时候是花钱找tb帮忙做的，这次打算记录下来这个过程，以便后续复现。&lt;/p&gt;
&lt;h2 id=&quot;安装min</summary>
      
    
    
    
    
    <category term="C++" scheme="https://nobodyyj.github.io/tags/C/"/>
    
    <category term="踩坑记录" scheme="https://nobodyyj.github.io/tags/%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/"/>
    
  </entry>
  
  <entry>
    <title>Barra CNE5</title>
    <link href="https://nobodyyj.github.io/post/8d2ea662.html"/>
    <id>https://nobodyyj.github.io/post/8d2ea662.html</id>
    <published>2024-01-03T01:50:48.000Z</published>
    <updated>2024-01-29T14:56:52.664Z</updated>
    
    <content type="html"><![CDATA[<h1 id="barra-cne5">Barra CNE5</h1><h2 id="前言">1.前言</h2><p>本文旨在记录自己在学习和使用Barra CNE5模型的过程，方便未来回忆。</p><h2 id="cne5模型简介">2.CNE5模型简介</h2><p>​ CNE5 是 Barra的最新一代面向中国股票市场的多因子模型。<strong>该模型考虑了一个国家因子、多个行业因子以及多个风格因子。</strong>假设市场中共有N 支股票，P 个行业，以及 Q个风格因子。在任意给定时间点，该模型使用因子暴露和个股收益率构建<strong>截面回归（cross-sectionalregression）</strong>如下：</p><p><span class="math inline">\(\begin{aligned} &amp;{\left[\begin{array}{c}r_1-r_f \\ r_2-r_f \\ \vdots \\r_N-r_f\end{array}\right]=\left[\begin{array}{c}1 \\ 1 \\1\end{array}\right] f_C+\left[\begin{array}{c}X_1^{I_1} \\ X_2^{I_1} \\\vdots \\ X_N^{I_1}\end{array}\right]f_{I_1}+\cdots+\left[\begin{array}{c}X_1^{I_P} \\ X_2^{I_P} \\ \vdots \\X_N^{I_P}\end{array}\right] f_{I_P}+\left[\begin{array}{c}X_1^{S_1} \\X_2^{S_1} \\ \vdots \\ X_1^{S_1} \\ X_2^{S_Q} \\ \vdots \\X_N^{S_Q}\end{array}\right] f_{S_Q}+\left[\begin{array}{c}u_1 \\ u_2 \\\vdots \\ u_N\end{array}\right]}\end{aligned}\)</span></p><p>​ 其中 <span class="math inline">\(r_n\)</span> 是第 <span class="math inline">\(\mathrm{n}\)</span> 支股票的收益率， <span class="math inline">\(r_f\)</span> 是无风险收益率。 <span class="math inline">\(X_n^{I_p}\)</span> 是股票 <span class="math inline">\(\mathrm{n}\)</span> 在行业 <span class="math inline">\(I_p\)</span>的暴露，如果假设一个公司只能属于一个行业，那么 <span class="math inline">\(X_n^{I_p}\)</span> 的取值为 0(代表该股票不属于这个行业) 或者 1 (代表该股票属于这个行业)。 <span class="math inline">\(X_n^{S_q}\)</span> 是股票 <span class="math inline">\(\mathrm{n}\)</span> 在风格因子 <span class="math inline">\(S_q\)</span> 的暴露，它的取值经过了某种标准化（标准化的方法会在下文说明）。 <span class="math inline">\(u_n\)</span>为股票 <span class="math inline">\(\mathrm{n}\)</span>的超额收益中无法被因子解释的部分，因此也被称为该股票的特异性收益。 <span class="math inline">\(f_C\)</span>为国家因子的因子收益率（所有股票在国家因子上的暴露都是1）； <span class="math inline">\(f_{I_p}\)</span> 为行业 <span class="math inline">\(I_p\)</span> 因子的因子收益率; <span class="math inline">\(f_{S_q}\)</span> 为风格因子 <span class="math inline">\(S_q\)</span> 的因子收益率。</p><p>​ 对于给定某一期截面数据（记为 <span class="math inline">\(\mathrm{T}\)</span> 期），在截面回归时，Barra采用期初的因子暴露取值（等价于 <span class="math inline">\(\mathrm{T}\)</span> - 1 期期末的因子暴露取值)和股票在 T 期内的收益率进行截面回归。在 USE4模型中，因子收益率是日频的，因此截面回归也应该是日频的，所以按照上述说明，在<span class="math inline">\(T-1\)</span> 日结束后更新因子的暴露，并利用T 日的股票收益率和因子暴露做截面回归。以下说明来自 Barra Risk ModelHandbook。</p><h2 id="barra10因子">3.Barra10因子</h2><figure><img src="/post/8d2ea662/image-20240129224012714.png" alt="image-20240129224012714"><figcaption aria-hidden="true">image-20240129224012714</figcaption></figure><figure><img src="/post/8d2ea662/image-20240129224028275.png" alt="image-20240129224028275"><figcaption aria-hidden="true">image-20240129224028275</figcaption></figure><h1 id="barra10因子的作用">4.Barra10因子的作用</h1><p>​在得到因子之后，可以从时序上，观察因子值、pnl时序上与10因子的相关系数，来反应该因子在不同风格上的暴露。​此外，还可以考虑加入20DR观察该因子对股价反转因子的暴露。</p><h1 id="风格因子">5.风格？因子？</h1><p>​什么是风格因子，什么是异象因子呢？换言之，我们能否自行选择合适的风格因子来检验某一因子在该方面的风险暴露程度，这个问题值得继续研究。之前在刷研报的时候，似乎也有研究员对size市值因子到底是算风格还是一个市场异象进行过讨论，但是笔者写到这里的时候不记得了（2024-1-2922:46:26），将带着这个问题继续学习~</p><h2 id="参考文献">参考文献</h2><p>1.<a href="https://zhuanlan.zhihu.com/p/38280638">正确理解 Barra的纯因子模型</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;barra-cne5&quot;&gt;Barra CNE5&lt;/h1&gt;
&lt;h2 id=&quot;前言&quot;&gt;1.前言&lt;/h2&gt;
&lt;p&gt;本文旨在记录自己在学习和使用Barra CNE5模型的过程，方便未来回忆。&lt;/p&gt;
&lt;h2 id=&quot;cne5模型简介&quot;&gt;2.CNE5模型简介&lt;/h2&gt;</summary>
      
    
    
    
    
    <category term="学习" scheme="https://nobodyyj.github.io/tags/%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="量化" scheme="https://nobodyyj.github.io/tags/%E9%87%8F%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>学习资源整理</title>
    <link href="https://nobodyyj.github.io/post/bb04665f.html"/>
    <id>https://nobodyyj.github.io/post/bb04665f.html</id>
    <published>2023-12-14T03:10:12.000Z</published>
    <updated>2024-01-04T15:41:19.892Z</updated>
    
    <content type="html"><![CDATA[<p>用于记录我找到的好的学习资源，以便厘清学习的优先度</p><h2 id="一量化平台框架">一、量化平台&amp;框架</h2><h3 id="backtrader">1.BackTrader</h3><p><a href="https://github.com/QuantWorld2022/backtrader">QuantWorld2022/backtrader(github.com)</a></p><h3 id="vnpy">2.Vnpy</h3><p><a href="https://github.com/vnpy/vnpy_algotrading">vnpy/vnpy_algotrading:VeighNa框架的算法交易模块 (github.com)</a></p><h3 id="qlib">3.Qlib</h3><p><a href="https://github.com/microsoft/qlib">[microsoft/qlib: Qlib isan AI-oriented quantitative investment platform that aims to realize thepotential, empower research, and create value using AI technologies inquantitative investment, from exploring ideas to implementingproductions. Qlib supports diverse machine learning modeling paradigms.including supervised learning, market dynamics modeling, and RL.(github.com)](https://github.com/microsoft/qlib)</a></p><h2 id="二python库">二、Python库</h2><h3 id="基于机器学习的凸优化库">1.基于机器学习的凸优化库</h3><p><a href="https://github.com/cvxgrp/cvxpylayers">cvxgrp/cvxpylayers:Differentiable convex optimization layers (github.com)</a></p><h3 id="mlflow">2.mlflow</h3><p><a href="https://www.mlflow.org/">mlflow</a> 用于学习如何管理machinelearning项目周期，并以此作为突破口加深对qlib work flow的认知</p><h2 id="三机器学习">三、机器学习</h2><h3 id="qlib-1">1.Qlib</h3><p><a href="https://github.com/microsoft/qlib">[microsoft/qlib: Qlib isan AI-oriented quantitative investment platform that aims to realize thepotential, empower research, and create value using AI technologies inquantitative investment, from exploring ideas to implementingproductions. Qlib supports diverse machine learning modeling paradigms.including supervised learning, market dynamics modeling, and RL.(github.com)](https://github.com/microsoft/qlib)</a></p><h3 id="深度学习">2.深度学习</h3><p><a href="https://github.com/d2l-ai/d2l-zh">d2l-ai/d2l-zh:《动手学深度学习》：面向中文读者、能运行、可讨论。中英文版被70多个国家的500多所大学用于教学。(github.com)</a></p><h2 id="aaamlp">3.AAAMLP</h2><p>https://ytzfhqs.github.io/AAAMLP-CN/</p><p>https://github.com/abhishekkrthakur/approachingalmost/tree/master</p><h2 id="四协方差学习">四、协方差学习</h2><p>shit我居然看不懂一点</p><p><a href="https://mp.weixin.qq.com/s?__biz=MzIyMDEwNDk1Mg==&amp;mid=2650877818&amp;idx=1&amp;sn=79f7794bdaf45b347e9bde0378bc89bc&amp;chksm=8c249eedbb5317fbaa4796aec3837498f2ab3b57b8cc6a21afb0f78a83eb76217d56d8d0c8f2&amp;scene=21#wechat_redirect">正确理解Barra 的纯因子模型</a></p><p><a href="https://mp.weixin.qq.com/s?__biz=MzIyMDEwNDk1Mg==&amp;mid=2650882346&amp;idx=1&amp;sn=b8a6d65936c082823c1615b6407139ed&amp;chksm=8c24f0bdbb5379ab54ef5c746ae778ed0e7637aece2f3700aea1cc4db4aaaf1e01c5f68cf7d9&amp;scene=132&amp;exptype=timeline_recommend_article_extendread_samebiz#wechat_redirect">Ledoitand Wolf 的协方差矩阵收缩之旅</a></p><p><a href="https://mp.weixin.qq.com/s/XM4VzcSBmkVnq_YgujSrjg">协方差矩阵的估计和评价方法【天风金工因子选股系列之七】</a></p><p><a href="https://zhuanlan.zhihu.com/p/166111933">Machine Learning forAsset Managers 笔记-Chapter2 - 知乎 (zhihu.com)</a></p><h2 id="四协方差学习-1">四、协方差学习</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;用于记录我找到的好的学习资源，以便厘清学习的优先度&lt;/p&gt;
&lt;h2 id=&quot;一量化平台框架&quot;&gt;一、量化平台&amp;amp;框架&lt;/h2&gt;
&lt;h3 id=&quot;backtrader&quot;&gt;1.BackTrader&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com</summary>
      
    
    
    
    
    <category term="实习" scheme="https://nobodyyj.github.io/tags/%E5%AE%9E%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>第一次高频交易比赛赛后感悟</title>
    <link href="https://nobodyyj.github.io/post/d5a2488e.html"/>
    <id>https://nobodyyj.github.io/post/d5a2488e.html</id>
    <published>2023-12-10T15:13:28.000Z</published>
    <updated>2024-09-20T16:39:31.068Z</updated>
    
    <content type="html"><![CDATA[<h1 id="第一次高频交易比赛赛后感悟">第一次高频交易比赛赛后感悟</h1><p>​我的第一次量化比赛参赛之旅在今天画上了句号，总共350+队伍只有前50能进复赛，我最后以rank60止步初赛，感觉十分可惜。为了不浪费我这半个月来在高频研究熬的好几个夜，我决定赶在自己参赛经历淡忘前，趁热打铁写下我参加这个高频交易比赛的感悟。（2023.12.10，希望2024.12.10的我能干到决赛一雪前耻）。</p><p>​ 本次参赛的感悟可分为技术栈、微观实盘、宏观策略和未来学习方向。</p><h2 id="一技术栈">一、技术栈</h2><p>​这是我第一次与其他人合作代码，深刻认识到使用<strong>git</strong>进行代码协作的必要性。在版本回滚和合并多人工作成果方面，git的存在简直是雪中送炭，如果不使用这个工作流很可能项目会存在大量的<strong>bug和代码沟通障碍</strong>。</p><p>​此外，cpp是进行高频交易必不可少的语言，即使使用并行、异步、numba等库能大大提高python语言的运行速度，但是归根到底还得是c&amp;cpp。在获取远程交易所信息的时候，需要熟悉如何使用并行、异步等库来减少请求等待时间。</p><h2 id="二微观实盘">二、微观实盘</h2><p>​这个方面是导致我止步初赛最关键的原因。在高频交易中，我认为因子很可能是一个黑箱一样的存在。如果不去检测实盘交易后LOB的变化情况、也不去监控订单的执行状态（比如是否挂单成功、是否完全成交、是否撤单成果），策略的收益来源完全是凭运气的（2023.12.10下午求神拜佛希望自己持仓标的涨一涨这种傻X操作太搞笑了）。</p><p>​以九坤的这次股票模拟交易比赛为例，下单、撤单、查询订单状态、获取股票实时LOB、获取UserPnL、Sharpe等数据都是需要通过调用api接口的，而这个API接口是具有上限的。从流程上来说，我需要在交易信号发出后，找到标的的code输入buyprice&amp;buy volume，并记录下response的orderindex，买单报单成功后，再根据orderindex查询订单的成交状态，交易成功后，再根据实时的盘口价格，计算出对应的sellprice&amp;sell volume，报送给交易所。如果sellorder报单成功，再记录下sell order的orderindex，再下一次开盘前or本次收盘后查询sell order的trade volume&amp;remain volume，完成实时头寸状态监控。比如如果我sell了800shares，只有500share traded，还剩下的300share会冻结，如果此时bidprice下跌，低于我的sellprice，我的这部分头寸就必须要撤回再次挂出300share&amp;bidprice1的卖单，<strong>否则就会存在风险敞口暴露，策略的收益被beta所取代</strong>。</p><p>​除了这个订单管理系统之外，止盈止损、下单仓位控制等操作，也是非常重要的模块，如果不完善这几个模块，是没有办法控制好策略的pnl，甚至没有办法控制好策略的收益来源。</p><h2 id="三宏观策略">三、宏观策略</h2><p>​宏观角度，本次比赛超脱了我所习惯的股票基本面信息，完全是从量价的角度来进行日内回转的股票交易。目前我认为，高频交易最重要的不是玩成梭哈式的读博游戏，而是通过高速执行的订单，完成短时间内的<strong>利润锁定</strong>or<strong>回撤控制</strong>，这个比写出一个好的alpha更加重要。如果要做高频操作，一定要完善各个模块，厘清每一笔交易信号发出后，持仓标的、可用资金、多头市值是否符合自己的策略，这个环节在执行中真的是想起来简单做起来难。</p><h2 id="四未来学习方向">四、未来学习方向</h2><p>​ 1.<strong>RL、DL，CNN、RNN类、GNN类、Tranformer、GAN</strong></p><p>​ 2.机器学习对于混频因子的融合、</p><p>​ 3.基于Markov转换的时序模型</p><p>​ 4.做市商策略</p><p>​ 5.幌骗策略</p><p>​6.更优秀、高效、快速的订单管理数据存储格式，比如我现在用的是dataframe，因为groupby函数很高效</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;第一次高频交易比赛赛后感悟&quot;&gt;第一次高频交易比赛赛后感悟&lt;/h1&gt;
&lt;p&gt;​
我的第一次量化比赛参赛之旅在今天画上了句号，总共350+队伍只有前50能进复赛，我最后以rank
60止步初赛，感觉十分可惜。为了不浪费我这半个月来在高频研究熬的好几个夜，我决定赶</summary>
      
    
    
    
    
    <category term="高频" scheme="https://nobodyyj.github.io/tags/%E9%AB%98%E9%A2%91/"/>
    
    <category term="学习" scheme="https://nobodyyj.github.io/tags/%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>股票形态相似度研究</title>
    <link href="https://nobodyyj.github.io/post/32dc4a05.html"/>
    <id>https://nobodyyj.github.io/post/32dc4a05.html</id>
    <published>2023-11-28T13:33:27.000Z</published>
    <updated>2023-11-28T13:41:58.561Z</updated>
    
    <content type="html"><![CDATA[<p><font color="red">1.东财数据+供应链数据</font></p><p><font color="red">2.对东财数据降噪处理，计算簇内</font></p><p><font color="red">3.在某一个时间节点，我们回看过去已知的概念数据or供应链数据</font></p><p><font color="red">机器学习做出来的效果不好，所以尝试对数据进行降噪处理</font></p><h1 id="section">11.27</h1><h3 id="具体操作">具体操作</h3><p>将概念算出来之后，得到每一天每个概念内股票的关系强度（比如等权的pearson系数），和宽基指数内的关系强度进行对比。可以尝试将concept内关系最弱的股票剔除，看概念内股票的关系有没有明显增强。</p><h3 id="先上手计算欧氏距离">先上手计算欧氏距离</h3><p>欧氏距离为常见的计算时间序列相似度的方法，该方法可以直接衡量两个时间序列之间的距离，其计算公式为:<span class="math display">\[D=\sqrt{\sum_{i=1}^N\left(X_i-Y_i\right)^2}\]</span></p><p>其中 <span class="math inline">\(\mathrm{N}\)</span> 为序列 <span class="math inline">\(\mathrm{X}\)</span> 和序列 <span class="math inline">\(\mathrm{Y}\)</span> 的长度。 由上述公式可以看出,若要计算两个序列之间的欧氏距离, 有两个局限性: 1、两个序列的长度需要相同,但在实际研究工作中, 找到满足上述条件的序列并非易事。2、该方法也无法进行异步相似度计算，因此会对实际上较为相似的两个时间序列其相似性做出误判。</p><h3 id="further-discussion">further discussion</h3><p>1.能不能做成因子</p><p>2.使用分钟频的数据是否会更有效？（or selected minutefrequency，比如volatility集聚现象重合）</p><h1 id="section-1">11.28</h1><p>从过往研究来看，度量时间序列相似性的方法大致分为4类：</p><p>第一类为<strong>基于特征的相似性度量方法</strong>，如相关系数、互信息等；第二类为<strong>锁步（时间序列“一对一”比较）的距离度量方法</strong>，典型方法有闵可夫斯基距离（可衍生为曼哈顿距离、欧氏距离、切比雪夫距离）、Hausdorff距离、余弦相似度等；第三类为<strong>弹性（允许时间序列“一对多”比较）的距离度量方法</strong>，代表方法为动态时间弯曲距离（DTW）、编辑距离（EDR）、最长公共子序列（LCSS）；第四类方法关注时间序列的<strong>变化相似性</strong>，如ARMA、HMM等。</p><h2 id="dtw">DTW</h2><h3 id="定义">定义</h3><p>对于时间序列 <span class="math inline">\(X\)</span> 和 <span class="math inline">\(Y\)</span> ，定义非负函数 <span class="math inline">\(f\)</span> 来衡量时间序列中的点 <span class="math inline">\(x \_\)</span>i和点 <span class="math inline">\(y\)</span> j的距离: <span class="math display">\[d(i, j)=f\left(x_{-} i, y \_j\right) \geq 0,\]</span></p><p>除常见的欧氏距离外，距离函数f也可以选取余弦相似度、汉明距离、曼哈顿距离、切比雪夫距离等其他距离度量方法。如果时间序列是多维的，则将每个维度的距离相加即可（确保各维度量纲一致）。</p><p>定义了时间序列中点与点的距离之后，两段时间序列即可形成一个 <span class="math inline">\(N \times M\)</span>的点阵，从点阵的右上角到左下角可以形成一条弯曲路径 (Warping Path)。</p><p>给定弯曲路径之后，便可以计算时间序列X和Y的标准化累计时间弯曲距离。另外，为了确保弯曲路径的合理性，通常需要满足3 大基本条件: - 终点条件 (EndpointConstraints)：要求弯曲路径的起点和终点必须为点阵平面的对角单元； -连续性条件 (Local ContinuityConstraints)：要求弯曲路径的每一步为相邻的单元（包括对角相邻单元)； -单调性条件 (MonotonicityConditions)：由于语音序列或证券交易数据等时间序列是有时序性的(时间不可倒流)，所以从实际意义出发，弯曲路径在点阵图上必须是单调的。</p><p>显然，满足以上3个条件的路径有很多条，选取哪条路径来计算DTW距离呢?一个很自然的想法是选取使得DTW距离最小的路径，具体推导过程需要利用动态规划算法（DynamicProgramming），这里不展开说明。最后，使得DTW距离最小化的最佳匹配路径需满足如下递归条件：<span class="math display">\[\delta(i, j)=d(i, j)+\min [\delta(i-1, j), \delta(i-1, j-1), \delta(i,j-1)]\]</span> <img src="/post/32dc4a05/640.png" alt="640"></p><h3 id="传统的dtw算法存在两点缺陷"><strong>传统的DTW算法存在两点缺陷</strong></h3><figure><img src="/post/32dc4a05/640%20(1).png" alt="640 (1)"><figcaption aria-hidden="true">640 (1)</figcaption></figure><p>1）算法对时间序列进行伸缩和平移时，可能存在过度伸缩或平移，产生时间序列点之间的“病态匹配”，如图8所示，B为两段时间序列的真实匹配情况，C为DTW算法下的匹配结果，显然较不合理，某些地方被过度平移和伸缩了</p><p>2）传统DTW算法运算量较大，时间复杂度较高。对于择时策略本身而言，显然第一个问题更加重要，如果不是高频策略，则运算复杂度对策略的影响不大，我们更关注距离度量的精度和策略实际效果。本节将针对“病态匹配”的问题对DTW算法做出改进，以提升匹配精度和策略效果。</p><hr><h3 id="病态匹配的改进方向">“病态匹配”的改进方向：</h3><p>加权DTW算法（Weighted Dynamic TimeWarping，WDTW）、导数DTW算法（Derivative Dynamic TimeWarping，DDTW）、步模式（Step Pattern）、全局约束（GlobalConstraints）</p><h4 id="全局约束-global-constraints">(1) 全局约束 (GlobalConstraints)</h4><p><strong>限制匹配路径尽可能接近对角线</strong>、<strong>对匹配路径整体进行限制</strong></p><p>传统的DTW算法允许匹配路径可以在图6中的点阵中任意生成（需满足上一节的3个基本条件），全局约束要求匹配路径只能在限定的区域内生成，常用的全局约束方法有Sakoe-ChibaConstraint和Itakura Parallelogram等。 Sakoe-ChibaConstraint，需设定窗口限制参数r，即最佳匹配路径须在距点阵对角线距离为r的区域内；ItakuraParallelogram将匹配路径限定在一个平行四边形区域中，平行四边形的四条边的斜率分别为2和0.5。</p><h4 id="局部约束local-constraints"><strong>(2) 局部约束（LocalConstraints）</strong></h4><p><strong>对匹配路径中每一步进行约束</strong></p><h5 id="a.步模式">a.<strong>步模式</strong></h5><p><strong>放松连续性条件，即可以与不相邻的点匹配，便能形成新的递归方式，即步模式</strong><img src="/post/32dc4a05/640%20(2).png" alt="640 (2)"></p><h5 id="b.加权方式">b.<strong>加权方式</strong></h5><figure><img src="/post/32dc4a05/640%20(3)-1701157416807-7.png" alt="640 (3)"><figcaption aria-hidden="true">640 (3)</figcaption></figure><p>模型有2个主要参数：序列长度l和距离阈值k，其中距离阈值k设置目的是当筛选相似的历史序列时，选取距离小于k的历史序列。若k选取过小，则会遗漏相似的历史序列；若k选取过大，则实际上不相似的历史序列也会被选入。</p><h3 id="我的问题">我的问题：</h3><p>1.能否利用聚类算法通过计算出DTW的相关度从而二次聚类？</p><p>做法参考：https://mp.weixin.qq.com/s/ODXny7pqV12LQ59TDkFkcQ</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;font color=&quot;red&quot;&gt;1.东财数据+供应链数据&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;&lt;font color=&quot;red&quot;&gt;2.对东财数据降噪处理，计算簇内&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;&lt;font color=&quot;red&quot;&gt;3.在某一个时间节点，我们回看过去已知的概念数</summary>
      
    
    
    
    
    <category term="实习" scheme="https://nobodyyj.github.io/tags/%E5%AE%9E%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>实习思考</title>
    <link href="https://nobodyyj.github.io/post/e850ef3b.html"/>
    <id>https://nobodyyj.github.io/post/e850ef3b.html</id>
    <published>2023-11-12T04:35:38.000Z</published>
    <updated>2024-12-29T14:08:17.354Z</updated>
    
    <content type="html"><![CDATA[<h1 id="实习思考">实习思考</h1><h2 id="前言">前言</h2><p>​本文用来记录我在第一段量化实习中的思考，以及由此产生的关于学习方向的灵感。​update：2024-1-1600:10:57，最近和带教老师还有机器学习组的同事交流了一下，感觉量化的底层就是将多个不同频率信号的合成为一个超因子，在这个过程之后再基于金融、经济学的先验知识，对这个因子做风格、行业、换手率等方面的约束，<strong>信号合成</strong>才是关键。</p><h2 id="一对于整体">一、对于整体</h2><p>​“量化投资始终坚持以基本面为核心，同时结合价量信息的方式，立足从投资的本源看问题，以长期有效的逻辑出发构建基础框架，再与交易逻辑相融合。无论是基本面还是价量，对每一类信息都会深挖背后的逻辑与含义，在此基础上，采用传统数学建模与领先的人工智能和机器学习技术结合的方式，不断随着市场结构与交易行为进行优化迭代。”</p><p>1.是如何将基本面因子与量价因子结合的，使用有效前沿吗？</p><p>2.交易逻辑+基础框架，是指因子组合之后划分为某个风格框架吗？</p><p>3.因子表现较好的作为多因子框架的因子，表现较差的作为机器学习模型的因子吗？这两者是如何结合的呢，也是划分为某个风格的吗？如何判断市场结构和交易行为，这是涉及到根据微观结构调整权重吗？</p><h2 id="二挖因子">二、挖因子</h2><p>1.对于中低频的基本面因子，正确的挖掘模式是什么样的呢，有哪些挖掘方法，效率如何？</p><p>2.对于高频因子，如何判断因子是处于正常波动还是失效的状态</p><p>A:绩效归因</p><p>3.如何在收益率和可解释性（逻辑性）进行取舍</p><p>A:可解释性，以及如果sharpe够大也能直接怼。</p><h2 id="三因子组合">三、因子组合</h2><p>1.看完石川《因子投资方法与实践》后写</p><p>2.可以使用机器学习做组合优化。</p><blockquote><p>经典的多因子研究包括 alpha因子的挖掘和期货组合权重优化计算。市面常见的逻辑认为：任意期货都同时暴露于多种不同的风险因素下，这些风险因素的共同作用形成了期货合约价格的波动。通过对不同的风险因素以alpha因子的形式有效刻画，我们可以实现对期货收益率的分解，从而研究期货合约价格波动的原因。而最优的投资组合则应当是经过“剔除其余不稳定的因素干扰、充分暴露于alpha因子，并一般通过凸优化方法将对收益率的预测转化为组合权重”等若干步处理后的结果。这些步骤中也涉及到一些针对组合权重的约束条件的设置。</p></blockquote><p>技术栈：<code>凸优化层 cvxpylayers</code></p><p>简要来讲，它是一 个 python 库，在 CVXPY 的基础上整合了PyTorch、JAX和TensorFlow 的接口，便于用户在构造神经网络时来调用这些框架里的层以及建立可分的凸优化层。</p><p>3.要去计算single factor &amp; portfolio和Barra10因子的相关系数。</p><figure><img src="/post/e850ef3b/提取自中银证券_20201103-中银证券-中银证券量化权益投资系列报告（二）：有关Barra中国权益CNE5模型的思考（上）.png" alt="提取自中银证券_20201103-中银证券-中银证券量化权益投资系列报告（二）：有关Barra中国权益CNE5模型的思考（上）"><figcaption aria-hidden="true">提取自中银证券_20201103-中银证券-中银证券量化权益投资系列报告（二）：有关Barra中国权益CNE5模型的思考（上）</figcaption></figure><h2 id="四交易信号">四、交易信号</h2><h3 id="交易信号的分布需要服从norm吗">1.交易信号的分布需要服从norm吗？</h3><p>A：需要具体情况具体分析，比如需要分析异常值对应的标的是什么类型的。对于偏态厚尾信号的处理，可以使用powerrank，展成均匀分布后根据表现改变power分配头部alpha的权重。-2023.11.27</p><h3 id="根据计算出的alpha值如何分配position">2.根据计算出的alpha值如何分配position？</h3><p>A：INSN、过滤invalidpool后，对pwrk的alpha值的非nan值的头部50%做多、尾部50%做空。</p><p>目的：portfolio多空平衡、行业市值中性，尽量减少beta和在传统风格因子上的暴露。</p><h2 id="五回测框架">五、回测框架</h2><p><font color="blue">vn.py、Backtrader</font></p><p><strong><del>争取在2024年前使用backtrader跑一次回测</del></strong>已完成-2023.11.27</p><p><strong>补充：</strong>2024-3-20 已成功运行第一个crypto实盘策略。</p><h2 id="六绩效归因">六、绩效归因</h2><p>Brison框架</p><h2 id="七宏观择时框架">七、宏观择时框架</h2><p>基于周期理论、宏观数据，划分金融市场属于哪个时域（用RegimeSwitching、HMM类似思想的ML、RL模型）</p><p>针对这个问题，优先了解<strong>Temporal RoutingAdaptor（TRA）</strong>模型。</p><blockquote><p>针对股票收益率预测任务，采用<strong>Temporal RoutingAdaptor（TRA）模型</strong>，用以识别不同的交易模式，直面“市场规律具有时变特性”这一核心问题。期望为每只股票，在每个时刻，都能找到与之相适应的股票收益率预测器或预测器组合，从而达到更优的预测效果。为了防止输出结果集中在个别预测器，借鉴了最优传输问题（OT）来指导路由器的学习。</p><p>TRA模型最早由微软亚洲研究院在 2021 年 6 月发布于 arXiv ，并被 2021 年KDD国际数据挖掘与知识发现大会接收。原模型代码已经封装在QLib里，感兴趣的投资者可以自行下载测试。本文在原模型基础上进行修改和优化。</p></blockquote><p><a href="https://mp.weixin.qq.com/s/pSdRtVVegwn5w5tu3IIreQ?poc_token=HOYAeGWjlNdg2VF8t711Tsb2T_4ztnGQDu24dHle">【专题研究】DFQ-TRA：多交易模式学习因子挖掘系统(qq.com)</a></p><p><a href="实习思考\国泰君安_20220511_主动专题报告_“板块配置轮盘”之初探——尝试搭建宏观因子和A股板块轮动间的桥梁_王大霁王鹤_20220511.pdf">国泰君安_20220511_主动专题报告_“板块配置轮盘”之初探——尝试搭建宏观因子和A股板块轮动间的桥梁_王大霁王鹤_20220511.pdf</a></p><h2 id="八rl调参">八、RL调参</h2><p>通过RL模型，选择合适的训练长度和预测长度，并且学习对应的可视化效果</p><p><strong>争取在2024年寒假跑一次机器学习模型来解决问这个问题</strong>（未解决）</p><h2 id="九qlib">九、Qlib</h2><p>争取跑通qlib平台上用到的code，至少理解有哪些包、对应的功能https://mp.weixin.qq.com/s/W2xRQHrwphbl1Um7_BkGgQ</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;实习思考&quot;&gt;实习思考&lt;/h1&gt;
&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;​
本文用来记录我在第一段量化实习中的思考，以及由此产生的关于学习方向的灵感。
​update：2024-1-16
00:10:57，最近和带教老师还有机器学习组的同事交流了一</summary>
      
    
    
    
    <category term="阶段性总结" scheme="https://nobodyyj.github.io/categories/%E9%98%B6%E6%AE%B5%E6%80%A7%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="实习" scheme="https://nobodyyj.github.io/tags/%E5%AE%9E%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>实习中的idea</title>
    <link href="https://nobodyyj.github.io/post/698179e8.html"/>
    <id>https://nobodyyj.github.io/post/698179e8.html</id>
    <published>2023-10-11T02:29:03.000Z</published>
    <updated>2024-12-29T14:08:09.190Z</updated>
    
    <content type="html"><![CDATA[<h2 id="如何根据市场交易规则最小交易单位来执行计算出的交易信号">1.如何根据市场交易规则（最小交易单位）来执行计算出的交易信号。</h2><p>(考虑交易手数的话，需要解一个以最小化持仓误差为目标函数的、以总资金为硬约束的整数线性规划问题)</p><h2 id="利用alpha值生成持仓信号">2.利用alpha值生成持仓信号</h2><p>在利用经过行业市值中性化、过滤掉涨跌停的final alphavalues计算对应的持仓比例、多空持仓情况时，可以考虑使用power rank。<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">cal_cs_rank</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> maxvalue<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>minvalue<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">'''    部分经过删除处理    '''</span>    res <span class="token operator">=</span> np_nan_array<span class="token punctuation">(</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token string">"float64"</span><span class="token punctuation">)</span>    res <span class="token operator">=</span> <span class="token punctuation">(</span>res <span class="token operator">-</span> np<span class="token punctuation">.</span>nanmin<span class="token punctuation">(</span>res<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>nanmax<span class="token punctuation">(</span>res<span class="token punctuation">)</span> <span class="token operator">-</span> np<span class="token punctuation">.</span>nanmin<span class="token punctuation">(</span>res<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>maxvalue <span class="token operator">-</span> minvalue<span class="token punctuation">)</span> <span class="token operator">+</span> minvalue    <span class="token keyword">return</span> res  <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>具体是把因子先利用rank函数展成(-1,1)的均匀分布形式，再根据对于头部权重的考虑，对展开后的值取3次方、5次方。</p><p><strong>1次方就是均匀分布</strong></p><pre class="line-numbers language-python" data-language="python"><code class="language-python">plot_distribution<span class="token punctuation">(</span>Analyzer<span class="token punctuation">.</span>industry_analyze_detail<span class="token punctuation">(</span><span class="token string">'2021-03-29'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'factor'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span><span class="token string">'power=1'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><figure><img src="/post/698179e8/1次.png" alt="1次"><figcaption aria-hidden="true">1次</figcaption></figure><p>取奇次幂可以放大头部权重</p><table><colgroup><col style="width: 50%"><col style="width: 50%"></colgroup><thead><tr class="header"><th>power=3</th><th>power=5</th></tr></thead><tbody><tr class="odd"><td><code>plot_distribution(tmp**3,'power=3')</code></td><td><code>plot_distribution(tmp**5,'power=5')</code></td></tr><tr class="even"><td><img src="/post/698179e8/3次.png" alt="3次"></td><td><img src="/post/698179e8/5次.png" alt="5次"></td></tr></tbody></table><h2 id="回测计算的是单利">3.回测计算的是单利</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">df<span class="token punctuation">[</span><span class="token string">'ac_returns'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'returns'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="因子组合优化的最简单形式">4.因子组合优化的最简单形式</h2><p>本报告根据模型滚动训练和预测的结果，将所有测试集上的预测结果作为最终合成的打分输出用于策略组合构建，每5个交易日进行一次调仓，仓位调整逻辑是在一定的约束条件下最大化加权模型预测打分值，同时限制组合的换手。每次调仓日的模型预测输出的股票得分向量记为<span class="math inline">\(\text{score}_{t}\)</span>，当期目标权重向量记为<span class="math inline">\(w_t\)</span>，优化目标方程为: <span class="math display">\[\begin{aligned}&amp; \max \left(\sum_{i=1}^n w_{t, i} * \text { score }_{t,i}-\alpha\left|w_t-w_{t-1}\right|\right) \\&amp; \text { s.t }\left\{\begin{array}{l}-0.005 I \leq w_t-w_{\text {benchmark }} \leq 0.005 I \\\sum_{i=1}^n w_{t, i}=1 \\w_t \geq 0\end{array}\right.\end{aligned}\]</span> 其中，<span class="math inline">\(\alpha\)</span>用于约束换手率，取值 0.05 ；$w_{benchmark}$为股票的基准权重向量； 1 是所有元素为 1 的长度为 <span class="math inline">\(w_t\)</span>的向量，个股权重相对于基准成分股权重的偏离限制在正负<span class="math inline">\(0.5 \%\)</span> 内。策略每 5个交易日在收盘后通过上述优化目标和条件求解权重。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;如何根据市场交易规则最小交易单位来执行计算出的交易信号&quot;&gt;1.如何根据市场交易规则（最小交易单位）来执行计算出的交易信号。&lt;/h2&gt;
&lt;p&gt;(考虑交易手数的话，需要解一个以最小化持仓误差为目标函数的、以总资金为硬约束的整数线性规划问题)&lt;/p&gt;
&lt;h2 id=</summary>
      
    
    
    
    <category term="阶段性总结" scheme="https://nobodyyj.github.io/categories/%E9%98%B6%E6%AE%B5%E6%80%A7%E6%80%BB%E7%BB%93/"/>
    
    
    <category term="实习" scheme="https://nobodyyj.github.io/tags/%E5%AE%9E%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>搭建个人blog的资源&amp;遇到的问题及其解决方法</title>
    <link href="https://nobodyyj.github.io/post/7b3956b1.html"/>
    <id>https://nobodyyj.github.io/post/7b3956b1.html</id>
    <published>2023-09-17T14:17:26.000Z</published>
    <updated>2024-01-04T15:41:19.924Z</updated>
    
    <content type="html"><![CDATA[<h1 id="用来记录自己学习搭建个人blog的资料遇到的问题及其解决方法">用来记录自己学习搭建个人blog的资料&amp;遇到的问题及其解决方法</h1><h2 id="学习资料">学习资料</h2><p><a href="http://haiyong.site/post/cda958f2.html">Hexo+阿里云&amp;GitHub搭建个人博客 | 海拥 (haiyong.site)</a></p><p>https://www.fomal.cc/posts/e593433d.html 主题：Butterfly <a href="https://butterfly.js.org/posts/4aa8abbe/#代碼高亮主題">Butterfly安裝文檔(三) 主題配置-1 | Butterfly</a></p><h2 id="目前遇到的问题">目前遇到的问题</h2><h3 id="图挂了">图挂了</h3><figure><img src="/post/7b3956b1/image-20230917220037303.png" alt="image-20230917220037303"><figcaption aria-hidden="true">image-20230917220037303</figcaption></figure><p><strong>解决方法</strong>：要使用相对路径“./搭建个人blog的资源-遇到的问题及其解决方法/image-20230917220037303.png”</p><h3 id="目录是乱的">目录是乱的</h3><p><img src="/post/7b3956b1/image-20230917220254151.png" alt="image-20230917220254151"><br><strong>解决方法</strong>：直接删除手动加上的数字，“# ##”会自动排序</p><h3 id="在多台电脑之间使用git进行数据同步时因为proxy问题报错">在多台电脑之间使用Git进行数据同步时因为proxy问题报错</h3><p>出现</p><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">fatal: unable to access &#39;XXX&#39;: Recv failure: Connection was reset<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p><strong>解决办法：</strong></p><ol type="1"><li><p>依次将如下两条语句复制到git中后，点击回车</p><pre class="line-numbers language-python" data-language="python"><code class="language-python">git config <span class="token operator">-</span><span class="token operator">-</span><span class="token keyword">global</span> <span class="token operator">-</span><span class="token operator">-</span>unset http<span class="token punctuation">.</span>proxy git config <span class="token operator">-</span><span class="token operator">-</span><span class="token keyword">global</span> <span class="token operator">-</span><span class="token operator">-</span>unset https<span class="token punctuation">.</span>proxygit config <span class="token operator">-</span><span class="token operator">-</span><span class="token keyword">global</span> http<span class="token punctuation">.</span>proxy http<span class="token punctuation">:</span><span class="token operator">//</span>手动设置代理荔枝<span class="token punctuation">:</span>端口<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li><li><p>在cmd中输入（用来清理DNS缓存）</p><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">ipconfig&#x2F;flushdns<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li><li><p>正常输入</p><pre class="line-numbers language-cmd" data-language="cmd"><code class="language-cmd">git add .git commit -m &quot;xxxx&quot;git push<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li></ol><h3 id="多台电脑之间协同工作的方法">多台电脑之间协同工作的方法</h3><p>摘自：https://xiaorui2.github.io/2019/05/25/Hexo%E5%8D%9A%E5%AE%A2%E5%A4%9A%E5%8F%B0%E7%94%B5%E8%84%91/</p><p>思路：<strong>使用git分支</strong>。</p><h1 id="准备工作和环境要求">准备工作和环境要求</h1><p>在这之前，首先你得有台电脑是配置好了的，也就是确保你已经使用<code>hexo</code>在<code>github pages</code>上面部署好你的个人博客，并在本地电脑拥有该博客的部署环境，即类似于以下图片的文件目录</p><p><a href="https://xiaorui2.github.io/2019/05/25/Hexo博客多台电脑/1.png"><img src="https://xiaorui2.github.io/2019/05/25/Hexo%E5%8D%9A%E5%AE%A2%E5%A4%9A%E5%8F%B0%E7%94%B5%E8%84%91/1.png" alt="img"></a></p><h1 id="对username.github.io仓库新建分支并克隆">对username.github.io仓库新建分支，并克隆</h1><p>在Github的<code>username.github.io</code>仓库上新建一个<code>xxx</code>分支，并切换到该分支，并在该仓库-&gt;<code>Settings</code>-&gt;<code>Branches</code>-&gt;<code>Default branch</code>中将默认分支设为<code>xxx</code>，<code>save</code>保存；然后将该仓库克隆（必须要用命令行）到本地，进入该<code>username.github.io</code>文件目录。</p><p>完成上面步骤后，在当前目录使用<code>Git Bash</code>执行<code>git branch</code>命令查看当前所在分支，应为新建的分支<code>xxx</code></p><h1 id="将本地博客的部署文件拷贝进username.github.io文件目录并提交">将本地博客的部署文件拷贝进username.github.io文件目录并提交</h1><p>将本地博客的部署文件全部拷贝进<code>username.github.io</code>文件目录，将拷贝进来的博客<code>hexo</code>部署环境提交到<code>xxx</code>分支，提交之前需注意：将<code>themes</code>目录以内中的主题的<code>.git</code>目录删除（如果有），因为一个<code>git</code>仓库中不能包含另一个<code>git</code>仓库，提交主题文件夹会失败。</p><p>执行<code>git add .</code>、<code>git commit -m 'back up hexo files'</code>（引号内容可改）、<code>git push</code>即可将博客的hexo部署环境提交到<code>GitHub</code>个人仓库的<code>xxx</code>分支。现在可以在GitHub上的<code>*username*.github.io</code>仓库看到两个分支的差异了。</p><p><code>master</code>分支和<code>xxx</code>分支各自保存着一个版本，<code>master</code>分支用于保存博客静态资源，提供博客页面供人访问；<code>xxx</code>分支用于备份博客部署文件，供自己维护更新，保证了两者在一个<code>GitHub</code>仓库内互不冲突。至此你搭配好的电脑上的任务就完成了。</p><h1 id="新电脑环境部署和更新">新电脑环境部署和更新</h1><p>首先你需要安装一下Hexo：</p><pre class="line-numbers language-none"><code class="language-none">npm install hexonpm installnpm install hexo-deployer-git --save<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre><p>然后将新电脑的生成的<code>ssh key</code>添加到<code>GitHub</code>账户上</p><p>在新电脑上克隆<code>username.github.io</code>仓库的<code>xxx</code>分支到本地，此时本地git仓库处于<code>xxx</code>分支</p><p>切换到<code>username.github.io</code>目录，执行<code>npm install</code>(由于仓库有一个<code>.gitignore</code>文件，里面默认是忽略掉<code>node_modules</code>文件夹的，也就是说仓库的<code>hexo</code>分支并没有存储该目录[也不需要]，所以需要<code>install</code>下.</p><p>然后就可以正常的编辑、撰写文章或其他博客更新改动。</p><p>依次执行<code>git add .</code>、<code>git commit -m 'back up hexo files'</code>（引号内容可改）、<code>git push</code>指令，保证<code>xxx</code>分支版本最新</p><p>执行<code>hexo d -g</code>指令（在此之前，有时可能需要执行<code>hexo clean</code>），完成后就会发现，最新改动已经更新到<code>master</code>分支了，两个分支互不干扰！</p><p><strong>注意</strong>：每次<strong>换电脑进行博客更新</strong>时，不管上次在其他电脑有没有更新（就怕更新之后忘了），最好先<code>git pull</code>获取<code>xxx</code>分支的最新版本，之后再进行编辑和提交。</p><p><a href="https://codeantenna.com/a/YRLydjyz7L">git WorkFlow</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;用来记录自己学习搭建个人blog的资料遇到的问题及其解决方法&quot;&gt;用来记录自己学习搭建个人blog的资料&amp;amp;遇到的问题及其解决方法&lt;/h1&gt;
&lt;h2 id=&quot;学习资料&quot;&gt;学习资料&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://haiyong.site/p</summary>
      
    
    
    
    
  </entry>
  
</feed>
